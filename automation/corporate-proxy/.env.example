# Corporate Proxy Configuration
# =============================
# Copy this file to .env and customize for your environment.
# Do not commit .env files to version control!

# ============================================
# Operating Mode Configuration
# ============================================

# Enable mock mode for local development/testing (true) or corporate mode for production (false)
USE_MOCK_API=true

# API mode: "crush", "opencode", or "gemini"
API_MODE=crush

# API version: "v1", "v2", or "v3"
API_VERSION=v3

# Debug mode for verbose logging
DEBUG_MODE=false

# ============================================
# Tool API Specification
# ============================================

# Tool API format: "openai" or "anthropic"
# - openai: Uses tool_calls array with function objects (default)
# - anthropic: Uses content array with tool_use blocks
# Auto-detection is enabled by default and will detect format from request
TOOL_API_SPEC=openai

# ============================================
# Corporate API Configuration
# ============================================

# Base URL for corporate AI API
COMPANY_API_BASE=https://bedrock.internal.company.com

# Authentication token for corporate API
COMPANY_API_TOKEN=your-corporate-api-token

# Custom endpoints for specific models (optional)
COMPANY_CLAUDE_ENDPOINT=ai-coe-bedrock-claude35-sonnet-200k
COMPANY_GPT4_ENDPOINT=ai-coe-bedrock-gpt4-turbo

# ============================================
# Proxy Port Configuration
# ============================================

# Gemini proxy port
GEMINI_PROXY_PORT=8053

# Crush proxy port
CRUSH_PROXY_PORT=8051

# OpenCode proxy port
OPENCODE_PROXY_PORT=8052

# Mock API port (for mock mode)
MOCK_API_PORT=8050

# ============================================
# Network Configuration
# ============================================

# HTTP proxy for corporate network (if required)
# HTTP_PROXY=http://proxy.company.com:8080
# HTTPS_PROXY=http://proxy.company.com:8080
# NO_PROXY=localhost,127.0.0.1

# ============================================
# Tool-Specific Configuration
# ============================================

# Maximum output size for Gemini tool responses (bytes)
GEMINI_MAX_OUTPUT_SIZE=102400

# ============================================
# Per-Model Tool Support Mode
# ============================================

# Override tool mode for specific models
# Format: <MODEL_NAME>_TOOL_MODE=native|text
# Examples:
# GPT4_TOOL_MODE=native
# CLAUDE_SONNET_TOOL_MODE=native
# CUSTOM_MODEL_TOOL_MODE=text

# ============================================
# Security Configuration
# ============================================

# Enable/disable specific security features (defaults to enabled)
# SANITIZE_ERROR_MESSAGES=true
# VALIDATE_INPUT_SCHEMAS=true
# RATE_LIMIT_ENABLED=true

# Rate limiting configuration (requests per minute)
# RATE_LIMIT_RPM=60
