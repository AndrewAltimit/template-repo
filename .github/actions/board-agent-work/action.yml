name: 'Board Agent Work'
description: 'Execute AI agent work from a GitHub Projects v2 board'
author: 'AndrewAltimit'

branding:
  icon: 'cpu'
  color: 'purple'

inputs:
  # Required inputs
  github-token:
    description: 'GitHub token for repository operations'
    required: true
  github-projects-token:
    description: 'GitHub classic token with project scope for board operations'
    required: true

  # Agent configuration
  agent-name:
    description: 'AI agent to use (claude, opencode, gemini, crush, codex)'
    required: false
    default: 'claude'
  agent-timeout:
    description: 'Timeout for agent execution in minutes'
    required: false
    default: '180'

  # Board configuration
  board-config-path:
    description: 'Path to board configuration file (ai-agents-board.yml)'
    required: false
    default: 'ai-agents-board.yml'
  max-issues:
    description: 'Maximum number of issues to work on'
    required: false
    default: '1'

  # Direct issue specification (for matrix job invocation)
  # When these are provided, the action skips the query step
  issue-number:
    description: 'Specific issue number to process (skips board query when provided)'
    required: false
    default: ''
  issue-title:
    description: 'Title of the issue (used with issue-number)'
    required: false
    default: ''
  issue-labels:
    description: 'Comma-separated labels for the issue (used with issue-number)'
    required: false
    default: ''

  # Label filtering (new)
  include-labels:
    description: 'Comma-separated labels to include (only process issues with these labels)'
    required: false
    default: ''
  exclude-labels:
    description: 'Comma-separated labels to exclude (skip issues with these labels)'
    required: false
    default: ''

  # Execution modes
  dry-run:
    description: 'Query work but do not execute (for testing)'
    required: false
    default: 'false'
  create-pr:
    description: 'Create PR after completing work'
    required: false
    default: 'true'

  # Observability (new)
  json-logging:
    description: 'Enable structured JSON logging for log aggregators'
    required: false
    default: 'false'

  # Janitor settings (new)
  stale-claim-threshold:
    description: 'Hours after which to consider a claim stale and clean it up'
    required: false
    default: '2'

  # OpenRouter configuration (for OpenCode, Crush agents)
  openrouter-api-key:
    description: 'OpenRouter API key for OpenCode/Crush agents'
    required: false

  # Gemini configuration
  gemini-api-key:
    description: 'Gemini API key for Gemini agent (also accepts GOOGLE_API_KEY)'
    required: false

  # Container configuration
  use-docker:
    description: 'Use Docker containers for agent execution'
    required: false
    default: 'true'
  docker-compose-file:
    description: 'Path to docker-compose.yml'
    required: false
    default: 'docker-compose.yml'

outputs:
  # Basic outputs
  has-work:
    description: 'Whether work was found on the board'
    value: ${{ steps.query.outputs.has_work }}
  issue-number:
    description: 'Issue number that was worked on'
    value: ${{ steps.query.outputs.issue_number }}
  issue-title:
    description: 'Title of the issue'
    value: ${{ steps.query.outputs.issue_title }}
  work-completed:
    description: 'Whether the agent completed work'
    value: ${{ steps.execute.outputs.work_completed }}
  pr-number:
    description: 'PR number if created'
    value: ${{ steps.create-pr.outputs.pr_number }}
  pr-url:
    description: 'PR URL if created'
    value: ${{ steps.create-pr.outputs.pr_url }}
  branch-name:
    description: 'Branch name created for work'
    value: ${{ steps.execute.outputs.branch_name }}

  # JSON summary output (new)
  summary-json:
    description: 'JSON summary of work performed'
    value: ${{ steps.summary.outputs.summary_json }}
  stale-claims-cleaned:
    description: 'Number of stale claims cleaned up'
    value: ${{ steps.janitor.outputs.cleaned_count }}

runs:
  using: 'composite'
  steps:
    # Step 1: Setup Rust binaries
    - name: Setup Rust binaries
      shell: bash
      env:
        JSON_LOGGING: ${{ inputs.json-logging }}
      run: |
        echo "::group::Setup Rust Binaries"

        # Check for board-manager binary in multiple locations (container-first philosophy)
        # Priority: 1) artifact download location, 2) local build location, 3) fail gracefully
        BOARD_MANAGER=""
        SEARCH_PATHS=(
          "${GITHUB_WORKSPACE}/rust-tools/board-manager"
          "${GITHUB_WORKSPACE}/tools/rust/board-manager/target/release/board-manager"
        )

        for path in "${SEARCH_PATHS[@]}"; do
          if [ -x "$path" ]; then
            BOARD_MANAGER="$path"
            echo "board-manager found at $BOARD_MANAGER"
            break
          fi
        done

        if [ -n "$BOARD_MANAGER" ]; then
          # Create symlinks for board-cli (used throughout the action)
          mkdir -p "$HOME/.local/bin"
          ln -sf "$BOARD_MANAGER" "$HOME/.local/bin/board-cli"
          ln -sf "$BOARD_MANAGER" "$HOME/.local/bin/board-manager"
          echo "PATH=$HOME/.local/bin:$PATH" >> $GITHUB_ENV
        else
          echo "::error::board-manager binary not found. Ensure the 'build-rust-tools' job runs first and artifacts are downloaded."
          echo "Searched paths:"
          for path in "${SEARCH_PATHS[@]}"; do
            echo "  - $path"
          done
          exit 1
        fi

        if [ "$JSON_LOGGING" = "true" ]; then
          echo '{"event": "setup_complete", "board_manager": "'$BOARD_MANAGER'"}'
        fi
        echo "::endgroup::"

    # Step 2: Validate board configuration
    - name: Validate board configuration
      shell: bash
      env:
        BOARD_CONFIG_PATH: ${{ inputs.board-config-path }}
        JSON_LOGGING: ${{ inputs.json-logging }}
      run: |
        echo "::group::Validate Board Configuration"
        if [ ! -f "$BOARD_CONFIG_PATH" ]; then
          if [ "$JSON_LOGGING" = "true" ]; then
            echo '{"event": "config_error", "error": "file_not_found", "path": "'$BOARD_CONFIG_PATH'"}'
          fi
          echo "::error::Board configuration file not found: $BOARD_CONFIG_PATH"
          exit 1
        fi
        if [ "$JSON_LOGGING" = "true" ]; then
          echo '{"event": "config_validated", "path": "'$BOARD_CONFIG_PATH'"}'
        else
          echo "Board config found: $BOARD_CONFIG_PATH"
        fi
        echo "::endgroup::"

    # Step 3: Janitor - Clean stale claims (uses Rust CLI)
    - name: Clean stale claims (Janitor)
      id: janitor
      shell: bash
      env:
        GITHUB_TOKEN: ${{ inputs.github-token }}
        GITHUB_PROJECTS_TOKEN: ${{ inputs.github-projects-token }}
        AGENT_NAME: ${{ inputs.agent-name }}
        BOARD_CONFIG_PATH: ${{ inputs.board-config-path }}
        STALE_THRESHOLD_HOURS: ${{ inputs.stale-claim-threshold }}
        JSON_LOGGING: ${{ inputs.json-logging }}
      run: |
        echo "::group::Janitor - Clean Stale Claims"

        # Note: Stale claim cleanup is now handled by the board-manager CLI
        # The release command with --reason=abandoned will clean up stale claims
        # For now, we just report that this step is a no-op until the Rust CLI
        # supports a dedicated janitor command
        #
        # TODO: Add 'board-manager janitor --agent NAME --threshold HOURS' command

        echo "cleaned_count=0" >> $GITHUB_OUTPUT

        if [ "$JSON_LOGGING" = "true" ]; then
          echo '{"event": "janitor_skip", "reason": "rust_cli_pending"}'
        else
          echo "Janitor: Skipped (Rust CLI support pending)"
        fi

        echo "::endgroup::"

    # Step 4: Sync approved issues to board
    - name: Sync approved issues to board
      id: sync-approved
      shell: bash
      env:
        GITHUB_TOKEN: ${{ inputs.github-token }}
        GITHUB_PROJECTS_TOKEN: ${{ inputs.github-projects-token }}
        AGENT_NAME: ${{ inputs.agent-name }}
        BOARD_CONFIG_PATH: ${{ inputs.board-config-path }}
        JSON_LOGGING: ${{ inputs.json-logging }}
      run: |
        echo "::group::Sync Approved Issues"
        # Rust binaries are used - no Python venv needed

        echo "=== Configuration ==="
        echo "Agent: $AGENT_NAME"
        echo "Board config: $BOARD_CONFIG_PATH"
        echo "Timestamp: $(date -Iseconds)"
        echo ""

        echo "=== Finding Approved Issues ==="
        echo "Using GitHub Search API to find [Approved][$AGENT_NAME] comments..."

        # Use board-cli to find approved issues (handles API calls internally)
        # Capture stderr separately for debugging while keeping stdout clean
        STDERR_FILE=$(mktemp)
        START_TIME=$(date +%s)

        if APPROVED_RESULT=$(board-cli --format json find-approved --agent "$AGENT_NAME" 2>"$STDERR_FILE"); then
          END_TIME=$(date +%s)
          echo "Search completed in $((END_TIME - START_TIME)) seconds"
          echo "Find approved result: $APPROVED_RESULT"

          # Parse and display results
          ISSUE_COUNT=$(echo "$APPROVED_RESULT" | python3 -c "import sys,json; print(len(json.load(sys.stdin)))" 2>/dev/null || echo "0")
          echo "Found $ISSUE_COUNT approved issues"

          # Add each approved issue that's not on board
          SYNCED=0
          NOT_ON_BOARD=$(echo "$APPROVED_RESULT" | python3 -c "import sys,json; [print(i['number']) for i in json.load(sys.stdin) if not i.get('on_board', True)]" 2>/dev/null || true)

          if [ -z "$NOT_ON_BOARD" ]; then
            echo "All approved issues are already on board"
          else
            for ISSUE_NUM in $NOT_ON_BOARD; do
              echo "Adding issue #$ISSUE_NUM to board..."
              ADD_STDERR=$(mktemp)
              if board-cli --format json add-to-board "$ISSUE_NUM" --agent "$AGENT_NAME" 2>"$ADD_STDERR"; then
                echo "Added issue #$ISSUE_NUM to board"
                SYNCED=$((SYNCED + 1))
              else
                echo "::warning::Failed to add issue #$ISSUE_NUM to board"
                if [ -s "$ADD_STDERR" ]; then
                  echo "Error details: $(cat "$ADD_STDERR")"
                fi
              fi
              rm -f "$ADD_STDERR"
            done
          fi

          echo "synced_count=$SYNCED" >> $GITHUB_OUTPUT
          echo "Synced $SYNCED approved issues to board"
        else
          EXIT_CODE=$?
          echo "::error::Find approved command failed with exit code $EXIT_CODE"
          if [ -s "$STDERR_FILE" ]; then
            echo "Error output:"
            cat "$STDERR_FILE"
          fi
          echo "synced_count=0" >> $GITHUB_OUTPUT
        fi

        rm -f "$STDERR_FILE"
        echo "::endgroup::"

    # Step 5: Query board for ready work (or use provided issue)
    - name: Query ready work
      id: query
      shell: bash
      env:
        GITHUB_TOKEN: ${{ inputs.github-token }}
        GITHUB_PROJECTS_TOKEN: ${{ inputs.github-projects-token }}
        AGENT_NAME: ${{ inputs.agent-name }}
        MAX_ISSUES: ${{ inputs.max-issues }}
        BOARD_CONFIG_PATH: ${{ inputs.board-config-path }}
        INCLUDE_LABELS: ${{ inputs.include-labels }}
        EXCLUDE_LABELS: ${{ inputs.exclude-labels }}
        JSON_LOGGING: ${{ inputs.json-logging }}
        # Direct issue specification (from matrix job)
        INPUT_ISSUE_NUMBER: ${{ inputs.issue-number }}
        INPUT_ISSUE_TITLE: ${{ inputs.issue-title }}
        INPUT_ISSUE_LABELS: ${{ inputs.issue-labels }}
      run: |
        echo "::group::Query Ready Work"

        # Check if issue was provided directly (from matrix job invocation)
        # This enables sequential processing of multiple issues with unique branches/PRs
        if [ -n "$INPUT_ISSUE_NUMBER" ]; then
          echo "=== Using Provided Issue (Matrix Job Mode) ==="
          echo "Issue number provided directly - skipping board query"
          echo "Issue: #$INPUT_ISSUE_NUMBER"
          echo "Title: $INPUT_ISSUE_TITLE"
          echo "Labels: ${INPUT_ISSUE_LABELS:-none}"

          ISSUE_NUMBER="$INPUT_ISSUE_NUMBER"
          ISSUE_TITLE="$INPUT_ISSUE_TITLE"
          ISSUE_LABELS="$INPUT_ISSUE_LABELS"
          HAS_WORK="True"

          # Build JSON safely using Python with env vars to handle ALL special characters
          # This avoids any shell quoting issues (triple quotes, backslashes, etc.)
          # Matches the schema from the standard query path for consistency
          QUERY_RESULT=$(INPUT_ISSUE_TITLE="$INPUT_ISSUE_TITLE" \
            INPUT_ISSUE_LABELS="$INPUT_ISSUE_LABELS" \
            ISSUE_NUMBER="$ISSUE_NUMBER" \
            python3 -c "
          import json
          import os
          title = os.environ.get('INPUT_ISSUE_TITLE', '')
          labels_str = os.environ.get('INPUT_ISSUE_LABELS', '')
          issue_number = int(os.environ.get('ISSUE_NUMBER', '0'))
          labels = [l.strip() for l in labels_str.split(',') if l.strip()] if labels_str else []
          print(json.dumps({
              'has_work': True,
              'issue_number': issue_number,
              'issue_title': title,
              'labels': labels,
              'total_ready': 1,
              'mode': 'matrix_provided'
          }))
          ")

          echo "has_work=$HAS_WORK" >> $GITHUB_OUTPUT
          echo "issue_number=$ISSUE_NUMBER" >> $GITHUB_OUTPUT
          echo "issue_title=$ISSUE_TITLE" >> $GITHUB_OUTPUT
          echo "issue_labels=$ISSUE_LABELS" >> $GITHUB_OUTPUT
          echo "query_result=$QUERY_RESULT" >> $GITHUB_OUTPUT

          echo "::endgroup::"
          exit 0
        fi

        # Rust binaries are used - no Python venv needed
        echo "=== Query Configuration ==="
        echo "Agent: $AGENT_NAME"
        echo "Max issues: $MAX_ISSUES"
        echo "Include labels: ${INCLUDE_LABELS:-none}"
        echo "Exclude labels: ${EXCLUDE_LABELS:-none}"
        echo "Timestamp: $(date -Iseconds)"
        echo ""

        # Build board-cli command using arrays to prevent command injection
        # This avoids eval and properly handles arguments with special characters
        CLI_CMD=(board-cli --format json ready --limit "$MAX_ISSUES" --approved-only)
        if [ -n "$AGENT_NAME" ]; then
          CLI_CMD+=(--agent "$AGENT_NAME")
        fi

        # Add label filters using IFS to properly handle comma-separated labels with spaces
        if [ -n "$INCLUDE_LABELS" ]; then
          IFS=',' read -ra LABELS <<< "$INCLUDE_LABELS"
          for label in "${LABELS[@]}"; do
            # Trim leading/trailing whitespace
            label=$(echo "$label" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
            CLI_CMD+=(--include-labels "$label")
          done
        fi
        if [ -n "$EXCLUDE_LABELS" ]; then
          IFS=',' read -ra LABELS <<< "$EXCLUDE_LABELS"
          for label in "${LABELS[@]}"; do
            label=$(echo "$label" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
            CLI_CMD+=(--exclude-labels "$label")
          done
        fi

        echo "=== Executing Query ==="
        echo "Command: ${CLI_CMD[*]}"

        # Query using board-cli (filtering handled by CLI)
        # Capture stderr separately for debugging
        STDERR_FILE=$(mktemp)
        START_TIME=$(date +%s)

        if READY_RESULT=$("${CLI_CMD[@]}" 2>"$STDERR_FILE"); then
          END_TIME=$(date +%s)
          echo "Query completed in $((END_TIME - START_TIME)) seconds"
          echo "Query result (JSON): $READY_RESULT"

          # Check if we got results (array with items)
          ISSUE_COUNT=$(echo "$READY_RESULT" | python3 -c "import sys,json; d=json.load(sys.stdin); print(len(d) if isinstance(d,list) else 0)" 2>/dev/null || echo "0")
          echo "Found $ISSUE_COUNT ready issues"

          if [ "$ISSUE_COUNT" -gt 0 ]; then
            # Extract first issue details
            FIRST_ISSUE=$(echo "$READY_RESULT" | python3 -c "import sys,json; print(json.dumps(json.load(sys.stdin)[0]))")
            ISSUE_NUMBER=$(echo "$FIRST_ISSUE" | python3 -c "import sys,json; print(json.load(sys.stdin).get('number', ''))")
            ISSUE_TITLE=$(echo "$FIRST_ISSUE" | python3 -c "import sys,json; print(json.load(sys.stdin).get('title', ''))")
            ISSUE_LABELS=$(echo "$FIRST_ISSUE" | python3 -c "import sys,json; print(','.join(json.load(sys.stdin).get('labels', [])))")
            HAS_WORK="True"
            # Build JSON safely using Python with env vars to handle ALL special characters
            # This avoids any shell quoting issues (quotes, backslashes, etc.)
            QUERY_RESULT=$(ISSUE_TITLE="$ISSUE_TITLE" \
              ISSUE_LABELS="$ISSUE_LABELS" \
              ISSUE_NUMBER="$ISSUE_NUMBER" \
              ISSUE_COUNT="$ISSUE_COUNT" \
              python3 -c "
            import json
            import os
            title = os.environ.get('ISSUE_TITLE', '')
            labels_str = os.environ.get('ISSUE_LABELS', '')
            issue_number = int(os.environ.get('ISSUE_NUMBER', '0'))
            total_ready = int(os.environ.get('ISSUE_COUNT', '0'))
            labels = [l.strip() for l in labels_str.split(',') if l.strip()] if labels_str else []
            print(json.dumps({
                'has_work': True,
                'issue_number': issue_number,
                'issue_title': title,
                'labels': labels,
                'total_ready': total_ready
            }))
            ")
            echo "Selected issue #$ISSUE_NUMBER: $ISSUE_TITLE"
          else
            HAS_WORK="False"
            QUERY_RESULT='{"has_work": false, "total_ready": 0}'
            echo "No ready work available"
          fi
        else
          EXIT_CODE=$?
          echo "::error::Query command failed with exit code $EXIT_CODE"
          if [ -s "$STDERR_FILE" ]; then
            echo "Error output:"
            cat "$STDERR_FILE"
          fi
          HAS_WORK="False"
          QUERY_RESULT='{"has_work": false, "error": "Query failed"}'
        fi

        rm -f "$STDERR_FILE"

        if [ "$JSON_LOGGING" = "true" ]; then
          echo "$QUERY_RESULT"
        else
          echo "Query result: $QUERY_RESULT"
        fi

        echo "has_work=$HAS_WORK" >> $GITHUB_OUTPUT
        echo "issue_number=$ISSUE_NUMBER" >> $GITHUB_OUTPUT
        echo "issue_title=$ISSUE_TITLE" >> $GITHUB_OUTPUT
        echo "issue_labels=$ISSUE_LABELS" >> $GITHUB_OUTPUT
        echo "query_result=$QUERY_RESULT" >> $GITHUB_OUTPUT

        if [ "$HAS_WORK" = "True" ]; then
          echo "Found work: Issue #$ISSUE_NUMBER - $ISSUE_TITLE"
        else
          echo "No ready work found for agent: $AGENT_NAME"
        fi

        echo "::endgroup::"

    # Step 5: Exit early if no work or dry run
    - name: Check if should continue
      id: should-continue
      shell: bash
      env:
        HAS_WORK: ${{ steps.query.outputs.has_work }}
        DRY_RUN: ${{ inputs.dry-run }}
      run: |
        if [ "$HAS_WORK" != "True" ]; then
          echo "No work to do - exiting"
          echo "continue=false" >> $GITHUB_OUTPUT
          exit 0
        fi

        if [ "$DRY_RUN" = "true" ]; then
          echo "Dry run mode - not executing work"
          echo "continue=false" >> $GITHUB_OUTPUT
          exit 0
        fi

        echo "continue=true" >> $GITHUB_OUTPUT

    # Step 6: Check for approval trigger (security check)
    - name: Check approval trigger
      id: approval
      if: steps.should-continue.outputs.continue == 'true'
      shell: bash
      env:
        GITHUB_TOKEN: ${{ inputs.github-token }}
        GITHUB_PROJECTS_TOKEN: ${{ inputs.github-projects-token }}
        ISSUE_NUMBER: ${{ steps.query.outputs.issue_number }}
        BOARD_CONFIG_PATH: ${{ inputs.board-config-path }}
        JSON_LOGGING: ${{ inputs.json-logging }}
      run: |
        echo "::group::Check Approval Trigger"
        # Rust binaries are used - no Python venv needed

        # Use the board-cli to check approval
        echo "Checking approval for issue #$ISSUE_NUMBER..."

        # Capture JSON only, discard stderr logs for clean parsing
        if APPROVAL_RESULT=$(board-cli --format json check-approval "$ISSUE_NUMBER" 2>/dev/null); then
          echo "Approval check result: $APPROVAL_RESULT"

          APPROVED=$(echo "$APPROVAL_RESULT" | python3 -c "import sys,json; print('true' if json.load(sys.stdin).get('approved') else 'false')" 2>/dev/null || echo "false")
          APPROVER=$(echo "$APPROVAL_RESULT" | python3 -c "import sys,json; print(json.load(sys.stdin).get('approver', ''))" 2>/dev/null || echo "")

          echo "approved=$APPROVED" >> $GITHUB_OUTPUT
          echo "approver=$APPROVER" >> $GITHUB_OUTPUT

          if [ "$APPROVED" = "true" ]; then
            echo "Issue #$ISSUE_NUMBER approved by $APPROVER"
          else
            echo "Issue #$ISSUE_NUMBER is not approved"
          fi
        else
          echo "::warning::Approval check failed: $APPROVAL_RESULT"
          echo "approved=false" >> $GITHUB_OUTPUT
          echo "approver=" >> $GITHUB_OUTPUT
        fi

        echo "::endgroup::"

    # Step 7: Claim work (only if approved)
    - name: Claim work
      id: claim
      if: steps.should-continue.outputs.continue == 'true' && steps.approval.outputs.approved == 'true'
      shell: bash
      env:
        GITHUB_TOKEN: ${{ inputs.github-token }}
        GITHUB_PROJECTS_TOKEN: ${{ inputs.github-projects-token }}
        ISSUE_NUMBER: ${{ steps.query.outputs.issue_number }}
        AGENT_NAME: ${{ inputs.agent-name }}
        BOARD_CONFIG_PATH: ${{ inputs.board-config-path }}
        JSON_LOGGING: ${{ inputs.json-logging }}
      run: |
        echo "::group::Claim Work"
        # Rust binaries are used - no Python venv needed

        SESSION_ID="gha-${{ github.run_id }}-${{ github.run_attempt }}"

        echo "=== Claiming Issue ==="
        echo "Issue: #$ISSUE_NUMBER"
        echo "Agent: $AGENT_NAME"
        echo "Session ID: $SESSION_ID"
        echo "Timestamp: $(date -Iseconds)"

        # Capture stderr for debugging while keeping stdout clean for JSON
        STDERR_FILE=$(mktemp)

        if CLAIM_RESULT=$(board-cli --format json claim "$ISSUE_NUMBER" --agent "$AGENT_NAME" --session "$SESSION_ID" 2>"$STDERR_FILE"); then
          echo "Claim result: $CLAIM_RESULT"

          SUCCESS=$(echo "$CLAIM_RESULT" | python3 -c "import sys,json; print('true' if json.load(sys.stdin).get('success') else 'false')" 2>/dev/null || echo "false")

          echo "claimed=$SUCCESS" >> $GITHUB_OUTPUT
          echo "session_id=$SESSION_ID" >> $GITHUB_OUTPUT

          if [ "$SUCCESS" = "true" ]; then
            echo "Successfully claimed issue #$ISSUE_NUMBER"
            echo "Claim comment posted to issue with session ID: $SESSION_ID"
          else
            REASON=$(echo "$CLAIM_RESULT" | python3 -c "import sys,json; print(json.load(sys.stdin).get('reason', 'unknown'))" 2>/dev/null || echo "unknown")
            echo "::error::Failed to claim issue #$ISSUE_NUMBER: $REASON"
            if [ -s "$STDERR_FILE" ]; then
              echo "Error details:"
              cat "$STDERR_FILE"
            fi
            rm -f "$STDERR_FILE"
            exit 1
          fi
        else
          EXIT_CODE=$?
          echo "::error::Claim command failed with exit code $EXIT_CODE"
          if [ -s "$STDERR_FILE" ]; then
            echo "Error output:"
            cat "$STDERR_FILE"
          fi
          echo "claimed=false" >> $GITHUB_OUTPUT
          echo "session_id=$SESSION_ID" >> $GITHUB_OUTPUT
          rm -f "$STDERR_FILE"
          exit 1
        fi

        rm -f "$STDERR_FILE"

        echo "::endgroup::"

    # Step 7: Create work branch (always from main)
    - name: Create work branch
      id: branch
      if: steps.claim.outputs.claimed == 'true'
      shell: bash
      env:
        ISSUE_NUMBER: ${{ steps.query.outputs.issue_number }}
        AGENT_NAME: ${{ inputs.agent-name }}
      run: |
        echo "::group::Create Work Branch"

        # Always create agent branches from main to ensure clean base
        echo "Fetching latest main branch..."
        git fetch origin main
        git checkout main
        git pull origin main

        BRANCH_NAME="agent/$AGENT_NAME/issue-$ISSUE_NUMBER"
        echo "Creating branch $BRANCH_NAME from main..."
        git checkout -b "$BRANCH_NAME"

        echo "branch_name=$BRANCH_NAME" >> $GITHUB_OUTPUT
        echo "Created branch: $BRANCH_NAME (from main)"

        echo "::endgroup::"

    # Step 8: Execute agent work
    - name: Execute agent work
      id: execute
      if: steps.claim.outputs.claimed == 'true'
      shell: bash
      env:
        GITHUB_TOKEN: ${{ inputs.github-token }}
        ISSUE_NUMBER: ${{ steps.query.outputs.issue_number }}
        ISSUE_TITLE: ${{ steps.query.outputs.issue_title }}
        AGENT_NAME: ${{ inputs.agent-name }}
        AGENT_TIMEOUT: ${{ inputs.agent-timeout }}
        USE_DOCKER: ${{ inputs.use-docker }}
        DOCKER_COMPOSE_FILE: ${{ inputs.docker-compose-file }}
        OPENROUTER_API_KEY: ${{ inputs.openrouter-api-key }}
        # Pass input as separate var; script will export GEMINI_API_KEY only if non-empty
        # This avoids overriding existing env vars from .env or docker-compose.yml
        INPUT_GEMINI_API_KEY: ${{ inputs.gemini-api-key }}
        BRANCH_NAME: ${{ steps.branch.outputs.branch_name }}
        JSON_LOGGING: ${{ inputs.json-logging }}
      run: |
        echo "::group::Execute Agent Work"
        # Rust binaries are used - no Python venv needed

        START_TIME=$(date +%s)

        # Use unique temp file path to avoid race conditions with concurrent jobs
        # RUNNER_TEMP is job-scoped, GITHUB_RUN_ID adds uniqueness
        PR_TITLE_DIR="${RUNNER_TEMP:-/tmp}"
        PR_TITLE_FILE="${PR_TITLE_DIR}/pr_title_${GITHUB_RUN_ID:-$$}.txt"
        PR_BODY_FILE="${PR_TITLE_DIR}/pr_body_${GITHUB_RUN_ID:-$$}.md"
        rm -f "$PR_TITLE_FILE" "$PR_BODY_FILE"  # Clean up any stale file from previous runs
        export PR_TITLE_FILE PR_BODY_FILE PR_TITLE_DIR

        if [ "$JSON_LOGGING" = "true" ]; then
          echo '{"event": "agent_start", "agent": "'$AGENT_NAME'", "issue": '$ISSUE_NUMBER', "timeout_min": '$AGENT_TIMEOUT'}'
        else
          echo "Agent: $AGENT_NAME"
          echo "Issue: #$ISSUE_NUMBER - $ISSUE_TITLE"
          echo "Branch: $BRANCH_NAME"
          echo "Timeout: ${AGENT_TIMEOUT}m"
        fi

        # Clean up large generated files that could cause token limit issues
        # These files are gitignored but may exist in the working directory
        # Delete ANY file matching these patterns (no size limit - they shouldn't exist)
        LARGE_FILES=(
          "bandit-report.json"
          "safety-report.json"
          "coverage.xml"
          ".coverage"
          "pylint-report.txt"
          "mypy-report.txt"
          "flake8-report.txt"
        )
        for pattern in "${LARGE_FILES[@]}"; do
          find . -name "$pattern" -type f -delete 2>/dev/null || true
        done
        # Also clean up any .log files larger than 100k
        find . -name "*.log" -type f -size +100k -delete 2>/dev/null || true
        # Clean up mypy cache if it somehow exists (shouldn't after fresh checkout)
        rm -rf .mypy_cache 2>/dev/null || true

        # Prepare context file for agent
        CONTEXT_FILE="/tmp/agent_context_$ISSUE_NUMBER.md"

        # Fetch issue body and comments using gh CLI
        # Comments provide valuable context like backlog refinements, architectural insights,
        # and approval reasoning that agents should consider during implementation
        export ISSUE_DATA=$(gh issue view "$ISSUE_NUMBER" --json body,comments 2>/dev/null || echo '{"body":"Unable to fetch issue","comments":[]}')
        ISSUE_BODY=$(echo "$ISSUE_DATA" | jq -r '.body // "Unable to fetch issue body"')

        # Format comments for inclusion in context, bucketed by trust level
        # Trust levels are defined in .agents.yaml security section:
        # - agent_admins: Users authorized to trigger agent actions (highest trust)
        # - trusted_sources: Trusted context providers (medium trust)
        # - other: All other commenters (lower trust, but still visible)
        #
        # Use board-manager symlink created in setup step (added to PATH)
        # Extract comments as JSON array
        COMMENTS_JSON=$(echo "$ISSUE_DATA" | jq -c '[.comments[]? | {author: .author.login, body: .body, createdAt: .createdAt}]' 2>/dev/null || echo '[]')

        if [ "$COMMENTS_JSON" != "[]" ]; then
          # Use Rust board-manager for trust bucketing
          # Pipe JSON via stdin to avoid ARG_MAX limits with large comment histories
          echo "Using Rust board-manager for comment bucketing"
          ISSUE_COMMENTS=$(echo "$COMMENTS_JSON" | board-manager bucket-comments 2>/dev/null || echo "")
        else
          ISSUE_COMMENTS=""
        fi

        # Write context using printf to avoid heredoc indentation issues in YAML
        # Note: No escaping needed - printf handles special chars correctly
        printf '%s\n' \
          "# Issue #$ISSUE_NUMBER: $ISSUE_TITLE" \
          "" \
          "## Issue Description" \
          "" \
          "$ISSUE_BODY" \
          "" \
          "$ISSUE_COMMENTS" \
          "" \
          "## Task" \
          "Implement the changes described in this issue." \
          "" \
          "## Requirements" \
          "- Create working, tested code" \
          "- Follow existing code patterns" \
          "- Add appropriate tests if the change warrants them" \
          "- Update documentation if needed" \
          "" \
          "## Critical Instructions" \
          "- IMPORTANT: For any file larger than 500 lines, use the Read tool with offset and limit parameters" \
          "- Example: Read(file_path='/path/to/file', offset=0, limit=200) to read first 200 lines" \
          "- Use Grep to search for specific content instead of reading entire large files" \
          "- Focus on the specific files mentioned in the issue - do not explore the entire codebase" \
          "- Run linting/tests after making changes: automation-cli ci run full" \
          "- DO NOT commit changes - the workflow handles commits automatically" \
          "" \
          "## PR Title Requirement" \
          "IMPORTANT: When you complete the task, you MUST write a descriptive PR title to $PR_TITLE_FILE" \
          "The title should:" \
          "- Use conventional commit format: type(scope): description" \
          "- Be specific about WHAT was changed, not just 'implement issue'" \
          "- Be concise (under 72 characters ideally)" \
          "Examples:" \
          "- chore: remove redundant setup.py files after PEP 621 migration" \
          "- fix(auth): resolve token refresh race condition" \
          "- feat(api): add pagination support to list endpoints" \
          "Write ONLY the title to the file, no other content." \
          "" \
          "## PR Description Requirement" \
          "IMPORTANT: You MUST also write a natural, human-readable PR description to $PR_BODY_FILE" \
          "" \
          "The description should read like a human wrote it:" \
          "- Start with 1-2 sentences explaining the problem/motivation" \
          "- Describe what the solution does in plain language" \
          "- List key changes with brief explanations if there are multiple" \
          "- NO robotic templates, statistics tables, or 'automated implementation' language" \
          "- NO sections like 'Files Changed' or 'Change Statistics' - these are auto-generated" \
          "" \
          "Good example:" \
          "---" \
          "This PR addresses a CI pipeline issue where sudo was hanging indefinitely." \
          "The solution replaces sudo with Docker-based permission fixing." \
          "" \
          "Key changes:" \
          "- Replace sudo with Docker containers for fixing file permissions" \
          "- Add timeout wrappers to prevent infinite hangs" \
          "- Implement symlink checks for security hardening" \
          "---" \
          "" \
          "Bad example (DO NOT write like this):" \
          "---" \
          "This automated pull request implements issue #123." \
          "## Files Changed  ## Statistics  +50 -20" \
          "---" \
          "" \
          "## Working Directory" \
          "You are on branch: $BRANCH_NAME" \
          "Make your changes and the workflow will commit and create a PR." \
          > "$CONTEXT_FILE"

        # Execute based on agent type
        WORK_COMPLETED="false"
        AGENT_ERROR=""

        case "$AGENT_NAME" in
          claude)
            # Claude always runs on host (requires subscription auth - cannot be containerized)
            if [ "$USE_DOCKER" = "true" ]; then
              echo "::notice::Claude requires host execution due to subscription auth - ignoring use-docker flag"
            fi
            if command -v claude &> /dev/null; then
              echo "Running Claude Code on host..."
              # --dangerously-skip-permissions required for CI/CD (no TTY for interactive prompts)
              # --print mode outputs response and exits (non-interactive)
              # --output-format json for structured output and error detection
              # Prompt piped via stdin (not positional arg) to avoid shell escaping issues
              CLAUDE_OUTPUT_FILE="/tmp/claude_output_$ISSUE_NUMBER.json"
              if timeout "${AGENT_TIMEOUT}m" claude \
                --print \
                --dangerously-skip-permissions \
                --output-format json \
                < "$CONTEXT_FILE" \
                > "$CLAUDE_OUTPUT_FILE"; then
                # Check JSON output for errors
                if [ -f "$CLAUDE_OUTPUT_FILE" ]; then
                  # Fail-safe: Check for empty file first
                  if [ ! -s "$CLAUDE_OUTPUT_FILE" ]; then
                    AGENT_ERROR="Claude produced empty output (possible silent crash)"
                    echo "::error::$AGENT_ERROR"
                  else
                    # Initialize to true (fail-safe) - only set to false if jq succeeds and finds no error
                    IS_ERROR="true"
                    if jq -e '.' "$CLAUDE_OUTPUT_FILE" > /dev/null 2>&1; then
                      IS_ERROR=$(jq -r '.is_error // false' "$CLAUDE_OUTPUT_FILE")
                    fi
                    if [ "$IS_ERROR" = "true" ]; then
                      ERRORS=$(jq -r '.errors | join("; ")' "$CLAUDE_OUTPUT_FILE" 2>/dev/null || echo "Unknown error")
                      AGENT_ERROR="Claude reported errors: $ERRORS"
                      echo "::error::$AGENT_ERROR"
                      cat "$CLAUDE_OUTPUT_FILE"
                    else
                      WORK_COMPLETED="true"
                      echo "Claude completed successfully"
                      # Show summary from JSON output
                      jq -r 'if .result then .result else . end' "$CLAUDE_OUTPUT_FILE" 2>/dev/null || cat "$CLAUDE_OUTPUT_FILE"
                    fi
                  fi
                else
                  AGENT_ERROR="Claude output file was not created"
                  echo "::error::$AGENT_ERROR"
                fi
              else
                EXIT_CODE=$?
                if [ $EXIT_CODE -eq 124 ]; then
                  AGENT_ERROR="Claude execution timed out after ${AGENT_TIMEOUT}m"
                else
                  AGENT_ERROR="Claude execution failed with exit code $EXIT_CODE"
                fi
                echo "::error::$AGENT_ERROR"
                # Show any output for debugging
                if [ -f "$CLAUDE_OUTPUT_FILE" ]; then
                  echo "Claude output:"
                  cat "$CLAUDE_OUTPUT_FILE"
                fi
              fi
              rm -f "$CLAUDE_OUTPUT_FILE"
            else
              AGENT_ERROR="Claude CLI not available on host"
              echo "::warning::$AGENT_ERROR"
            fi
            ;;

          opencode)
            if [ "$USE_DOCKER" = "true" ]; then
              echo "Running OpenCode in Docker..."
              if timeout "${AGENT_TIMEOUT}m" docker compose -f "$DOCKER_COMPOSE_FILE" run --rm \
                -e OPENROUTER_API_KEY \
                -e PR_TITLE_FILE \
                -e PR_BODY_FILE \
                -v "$PR_TITLE_DIR:$PR_TITLE_DIR" \
                openrouter-agents opencode run < "$CONTEXT_FILE"; then
                WORK_COMPLETED="true"
              else
                AGENT_ERROR="OpenCode Docker execution failed"
              fi
            elif command -v opencode &> /dev/null; then
              echo "Running OpenCode locally..."
              if timeout "${AGENT_TIMEOUT}m" opencode run < "$CONTEXT_FILE"; then
                WORK_COMPLETED="true"
              else
                AGENT_ERROR="OpenCode local execution failed"
              fi
            else
              AGENT_ERROR="OpenCode not available"
              echo "::warning::$AGENT_ERROR"
            fi
            ;;

          crush)
            if [ "$USE_DOCKER" = "true" ]; then
              echo "Running Crush in Docker..."
              if timeout "${AGENT_TIMEOUT}m" docker compose -f "$DOCKER_COMPOSE_FILE" run --rm \
                -e OPENROUTER_API_KEY \
                -e PR_TITLE_FILE \
                -e PR_BODY_FILE \
                -v "$PR_TITLE_DIR:$PR_TITLE_DIR" \
                openrouter-agents crush run < "$CONTEXT_FILE"; then
                WORK_COMPLETED="true"
              else
                AGENT_ERROR="Crush Docker execution failed"
              fi
            elif command -v crush &> /dev/null; then
              echo "Running Crush locally..."
              if timeout "${AGENT_TIMEOUT}m" crush run < "$CONTEXT_FILE"; then
                WORK_COMPLETED="true"
              else
                AGENT_ERROR="Crush local execution failed"
              fi
            else
              AGENT_ERROR="Crush not available"
              echo "::warning::$AGENT_ERROR"
            fi
            ;;

          gemini)
            # Only export API keys if input was provided; otherwise rely on .env/docker-compose.yml
            if [ -n "$INPUT_GEMINI_API_KEY" ]; then
              export GEMINI_API_KEY="$INPUT_GEMINI_API_KEY"
              export GOOGLE_API_KEY="$INPUT_GEMINI_API_KEY"
            fi

            if [ "$USE_DOCKER" = "true" ]; then
              echo "Running Gemini in Docker..."
              # Use array to safely handle paths with spaces
              DOCKER_CMD=(docker compose -f "$DOCKER_COMPOSE_FILE" run --rm)
              # Mount PR_TITLE_DIR so container can write agent-provided PR titles and bodies
              DOCKER_CMD+=(-e PR_TITLE_FILE -e PR_BODY_FILE -v "$PR_TITLE_DIR:$PR_TITLE_DIR")
              if [ -n "$INPUT_GEMINI_API_KEY" ]; then
                DOCKER_CMD+=(-e GEMINI_API_KEY -e GOOGLE_API_KEY)
              fi
              # Use 'gemini prompt' subcommand with stdin; bare 'gemini' enters interactive mode
              if timeout "${AGENT_TIMEOUT}m" "${DOCKER_CMD[@]}" \
                mcp-gemini gemini prompt --output-format text < "$CONTEXT_FILE"; then
                WORK_COMPLETED="true"
              else
                AGENT_ERROR="Gemini Docker execution failed"
              fi
            elif command -v gemini &> /dev/null; then
              echo "Running Gemini locally..."
              # Use 'gemini prompt' subcommand with stdin; bare 'gemini' enters interactive mode
              if timeout "${AGENT_TIMEOUT}m" gemini prompt --output-format text < "$CONTEXT_FILE"; then
                WORK_COMPLETED="true"
              else
                AGENT_ERROR="Gemini local execution failed"
              fi
            else
              AGENT_ERROR="Gemini not available"
              echo "::warning::$AGENT_ERROR"
            fi
            ;;

          codex)
            if [ "$USE_DOCKER" = "true" ]; then
              echo "Running Codex in Docker..."
              if timeout "${AGENT_TIMEOUT}m" docker compose -f "$DOCKER_COMPOSE_FILE" run --rm \
                -e PR_TITLE_FILE \
                -e PR_BODY_FILE \
                -v "$PR_TITLE_DIR:$PR_TITLE_DIR" \
                codex-agent codex < "$CONTEXT_FILE"; then
                WORK_COMPLETED="true"
              else
                AGENT_ERROR="Codex Docker execution failed"
              fi
            elif command -v codex &> /dev/null; then
              echo "Running Codex locally..."
              if timeout "${AGENT_TIMEOUT}m" codex < "$CONTEXT_FILE"; then
                WORK_COMPLETED="true"
              else
                AGENT_ERROR="Codex local execution failed"
              fi
            else
              AGENT_ERROR="Codex not available"
              echo "::warning::$AGENT_ERROR"
            fi
            ;;

          *)
            AGENT_ERROR="Unknown agent: $AGENT_NAME"
            echo "::error::$AGENT_ERROR"
            exit 1
            ;;
        esac

        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))

        # Read agent-provided PR title if available
        # PR_TITLE_FILE was set earlier in this step with a unique job-scoped path
        AGENT_PR_TITLE=""
        if [ -f "$PR_TITLE_FILE" ] && [ -s "$PR_TITLE_FILE" ]; then
          # Read first line, trim whitespace, limit to 200 chars
          # Use Python for UTF-8 safe truncation (cut -c and mawk substr are byte-based)
          AGENT_PR_TITLE=$(head -n 1 "$PR_TITLE_FILE" | python3 -c "import sys; s=sys.stdin.read().strip(); print(s[:200])")
          if [ -n "$AGENT_PR_TITLE" ]; then
            echo "Agent provided PR title: $AGENT_PR_TITLE"
          fi
          rm -f "$PR_TITLE_FILE"
        fi

        # Read agent-provided PR body if available
        AGENT_PR_BODY=""
        if [ -f "$PR_BODY_FILE" ] && [ -s "$PR_BODY_FILE" ]; then
          # Read entire file, limit to 10000 chars to prevent oversized PRs
          AGENT_PR_BODY=$(python3 -c "import sys; s=open('$PR_BODY_FILE').read().strip(); print(s[:10000])")
          if [ -n "$AGENT_PR_BODY" ]; then
            echo "Agent provided PR body (${#AGENT_PR_BODY} chars)"
          fi
          rm -f "$PR_BODY_FILE"
        fi

        echo "work_completed=$WORK_COMPLETED" >> $GITHUB_OUTPUT
        echo "branch_name=$BRANCH_NAME" >> $GITHUB_OUTPUT
        echo "duration_seconds=$DURATION" >> $GITHUB_OUTPUT
        echo "agent_error=$AGENT_ERROR" >> $GITHUB_OUTPUT
        # Escape PR title for GITHUB_OUTPUT: % -> %25, \r -> %0D, \n -> %0A
        ESCAPED_PR_TITLE=$(printf '%s' "$AGENT_PR_TITLE" | sed 's/%/%25/g; s/\r/%0D/g' | tr '\n' ' ')
        echo "agent_pr_title=$ESCAPED_PR_TITLE" >> $GITHUB_OUTPUT

        # Write PR body to a temp file and pass path via output (body can be multiline/large)
        # This avoids issues with escaping multiline content in GITHUB_OUTPUT
        PR_BODY_OUTPUT_FILE="${PR_TITLE_DIR}/pr_body_output_${GITHUB_RUN_ID:-$$}.md"
        if [ -n "$AGENT_PR_BODY" ]; then
          printf '%s' "$AGENT_PR_BODY" > "$PR_BODY_OUTPUT_FILE"
          echo "agent_pr_body_file=$PR_BODY_OUTPUT_FILE" >> $GITHUB_OUTPUT
        else
          echo "agent_pr_body_file=" >> $GITHUB_OUTPUT
        fi

        if [ "$JSON_LOGGING" = "true" ]; then
          echo '{"event": "agent_complete", "success": '$([[ "$WORK_COMPLETED" = "true" ]] && echo "true" || echo "false")', "duration_sec": '$DURATION', "error": "'$AGENT_ERROR'"}'
        fi

        echo "::endgroup::"

    # Step 9: Create PR if work completed
    - name: Create pull request
      id: create-pr
      if: steps.execute.outputs.work_completed == 'true' && inputs.create-pr == 'true'
      shell: bash
      env:
        GITHUB_TOKEN: ${{ inputs.github-token }}
        ISSUE_NUMBER: ${{ steps.query.outputs.issue_number }}
        ISSUE_TITLE: ${{ steps.query.outputs.issue_title }}
        AGENT_NAME: ${{ inputs.agent-name }}
        BRANCH_NAME: ${{ steps.execute.outputs.branch_name }}
        AGENT_PR_TITLE: ${{ steps.execute.outputs.agent_pr_title }}
        AGENT_PR_BODY_FILE: ${{ steps.execute.outputs.agent_pr_body_file }}
        JSON_LOGGING: ${{ inputs.json-logging }}
      run: |
        echo "::group::Create Pull Request"

        # Check if there are changes to commit
        if git diff --quiet && git diff --cached --quiet; then
          echo "No changes to commit"
          echo "pr_created=false" >> $GITHUB_OUTPUT
          if [ "$JSON_LOGGING" = "true" ]; then
            echo '{"event": "pr_skip", "reason": "no_changes"}'
          fi
          exit 0
        fi

        # Determine PR title: prefer agent-provided, fall back to issue-based
        if [ -n "$AGENT_PR_TITLE" ]; then
          # Agent provided a descriptive title - use it directly
          PR_TITLE="$AGENT_PR_TITLE"
          echo "Using agent-provided PR title: $PR_TITLE"
        else
          # Fall back to generic title with issue reference
          # Extract category from issue title if it starts with [Category]
          if [[ "$ISSUE_TITLE" =~ ^\[([^\]]+)\] ]]; then
            CATEGORY="${BASH_REMATCH[1]}"
            # Map common categories to commit types
            case "$CATEGORY" in
              Quality|Cleanup|Refactor) TYPE="chore" ;;
              Bug|Fix) TYPE="fix" ;;
              Feature|Enhancement) TYPE="feat" ;;
              Docs|Documentation) TYPE="docs" ;;
              Test|Testing) TYPE="test" ;;
              *) TYPE="feat" ;;
            esac
            # Remove category prefix from title for cleaner message
            CLEAN_TITLE=$(echo "$ISSUE_TITLE" | sed 's/^\[[^]]*\][[:space:]]*//')
            # Use cut -c for UTF-8 safe truncation (bash substring can split multibyte chars)
            TRUNCATED_TITLE=$(printf '%s' "$CLEAN_TITLE" | cut -c1-150)
            PR_TITLE="$TYPE: $TRUNCATED_TITLE"
          else
            # Use cut -c for UTF-8 safe truncation (bash substring can split multibyte chars)
            TRUNCATED_TITLE=$(printf '%s' "$ISSUE_TITLE" | cut -c1-120)
            PR_TITLE="feat: implement #$ISSUE_NUMBER - $TRUNCATED_TITLE"
          fi
          echo "Using generated PR title: $PR_TITLE"
        fi

        # Note: PR_TITLE is used directly in double-quoted shell arguments below,
        # which handles special characters correctly without manual escaping

        # Create commit message file using printf to avoid heredoc injection
        # (heredocs can be terminated early if variable content matches delimiter)
        COMMIT_MSG_FILE=$(mktemp)
        printf '%s\n\nImplements issue #%s: %s\n\nImplemented by %s agent.\n\nCloses #%s\n\nCo-Authored-By: %s <noreply@anthropic.com>\n' \
          "$PR_TITLE" \
          "$ISSUE_NUMBER" \
          "$ISSUE_TITLE" \
          "$AGENT_NAME" \
          "$ISSUE_NUMBER" \
          "$AGENT_NAME" \
          > "$COMMIT_MSG_FILE"

        # Commit changes using file-based message
        git add -A
        git commit -F "$COMMIT_MSG_FILE"
        rm -f "$COMMIT_MSG_FILE"

        # Push branch
        git push -u origin "$BRANCH_NAME"

        # Create PR body - prefer agent-provided description, fall back to simple template
        PR_BODY_FILE=$(mktemp)

        if [ -n "$AGENT_PR_BODY_FILE" ] && [ -f "$AGENT_PR_BODY_FILE" ]; then
          # Use agent-provided natural description
          echo "Using agent-provided PR description"
          cat "$AGENT_PR_BODY_FILE" > "$PR_BODY_FILE"

          # Append standard footer
          printf '\n\nCloses #%s\n' "$ISSUE_NUMBER" >> "$PR_BODY_FILE"
          rm -f "$AGENT_PR_BODY_FILE"
        else
          # Fall back to simple template (no robotic sections)
          echo "Using fallback PR description template"
          printf 'Implementation for issue #%s.\n\nCloses #%s\n' \
            "$ISSUE_NUMBER" "$ISSUE_NUMBER" > "$PR_BODY_FILE"
        fi

        # Create PR using file-based body (title already includes conventional commit type)
        PR_URL=$(gh pr create \
          --title "$PR_TITLE" \
          --body-file "$PR_BODY_FILE" \
          --base main \
          --head "$BRANCH_NAME")
        rm -f "$PR_BODY_FILE"

        PR_NUMBER=$(echo "$PR_URL" | grep -oE '[0-9]+$')

        echo "pr_created=true" >> $GITHUB_OUTPUT
        echo "pr_number=$PR_NUMBER" >> $GITHUB_OUTPUT
        echo "pr_url=$PR_URL" >> $GITHUB_OUTPUT

        if [ "$JSON_LOGGING" = "true" ]; then
          echo '{"event": "pr_created", "pr_number": '$PR_NUMBER', "pr_url": "'$PR_URL'"}'
        else
          echo "Created PR #$PR_NUMBER: $PR_URL"
        fi

        echo "::endgroup::"

    # Step 10: Release work claim
    - name: Release work claim
      if: always() && steps.claim.outputs.claimed == 'true'
      shell: bash
      env:
        GITHUB_TOKEN: ${{ inputs.github-token }}
        GITHUB_PROJECTS_TOKEN: ${{ inputs.github-projects-token }}
        ISSUE_NUMBER: ${{ steps.query.outputs.issue_number }}
        AGENT_NAME: ${{ inputs.agent-name }}
        WORK_COMPLETED: ${{ steps.execute.outputs.work_completed }}
        PR_CREATED: ${{ steps.create-pr.outputs.pr_created }}
        CREATE_PR_ENABLED: ${{ inputs.create-pr }}
        BOARD_CONFIG_PATH: ${{ inputs.board-config-path }}
        JSON_LOGGING: ${{ inputs.json-logging }}
      run: |
        echo "::group::Release Work Claim"
        # Rust binaries are used - no Python venv needed

        # Determine release reason
        # - pr_created: Work done, PR created - stay In Progress until PR is merged
        # - completed: Work done, no changes needed - stay In Progress for human review
        # - abandoned: Job cancelled - return to Todo
        # - error: Something went wrong - return to Todo for retry
        # NOTE: Agents NEVER mark issues as Done - that only happens when PRs are merged
        if [ "$WORK_COMPLETED" = "true" ]; then
          if [ "$PR_CREATED" = "true" ]; then
            REASON="pr_created"
          elif [ "$CREATE_PR_ENABLED" = "true" ]; then
            # PR was expected but not created (step failed or no changes)
            # Check if there were changes - if PR_CREATED=false, no changes; if empty, step failed
            if [ "$PR_CREATED" = "false" ]; then
              # No changes to commit - stay In Progress for human review
              REASON="completed"
            else
              # PR creation step failed - treat as error for retry
              REASON="error"
              echo "::warning::PR creation was expected but step did not complete successfully"
            fi
          else
            # PR was not expected (create-pr=false) - stay In Progress for human review
            REASON="completed"
          fi
        elif [ "${{ job.status }}" = "cancelled" ]; then
          REASON="abandoned"
        else
          REASON="error"
        fi

        echo "=== Releasing Claim ==="
        echo "Issue: #$ISSUE_NUMBER"
        echo "Agent: $AGENT_NAME"
        echo "Reason: $REASON"
        echo "Timestamp: $(date -Iseconds)"

        # Capture stderr for debugging while keeping stdout clean for JSON
        STDERR_FILE=$(mktemp)

        if RELEASE_RESULT=$(board-cli --format json release "$ISSUE_NUMBER" --agent "$AGENT_NAME" --reason "$REASON" 2>"$STDERR_FILE"); then
          echo "Release result: $RELEASE_RESULT"
          echo "Released claim with reason: $REASON"
        else
          EXIT_CODE=$?
          echo "::warning::Release command failed with exit code $EXIT_CODE"
          if [ -s "$STDERR_FILE" ]; then
            echo "Error output:"
            cat "$STDERR_FILE"
          fi
          echo "Release is best-effort, continuing..."
        fi

        rm -f "$STDERR_FILE"
        echo "::endgroup::"

    # Step 11: Generate JSON summary and Step Summary
    - name: Generate summary
      id: summary
      if: always()
      shell: bash
      env:
        HAS_WORK: ${{ steps.query.outputs.has_work }}
        ISSUE_NUMBER: ${{ steps.query.outputs.issue_number }}
        ISSUE_TITLE: ${{ steps.query.outputs.issue_title }}
        ISSUE_LABELS: ${{ steps.query.outputs.issue_labels }}
        WORK_COMPLETED: ${{ steps.execute.outputs.work_completed }}
        DURATION_SECONDS: ${{ steps.execute.outputs.duration_seconds }}
        AGENT_ERROR: ${{ steps.execute.outputs.agent_error }}
        PR_CREATED: ${{ steps.create-pr.outputs.pr_created }}
        PR_NUMBER: ${{ steps.create-pr.outputs.pr_number }}
        PR_URL: ${{ steps.create-pr.outputs.pr_url }}
        AGENT_NAME: ${{ inputs.agent-name }}
        DRY_RUN: ${{ inputs.dry-run }}
        STALE_CLEANED: ${{ steps.janitor.outputs.cleaned_count }}
        JSON_LOGGING: ${{ inputs.json-logging }}
      run: |
        # Build JSON summary
        PROCESSED=0
        SUCCEEDED=0
        FAILED=0
        PR_URLS="[]"

        if [ "$HAS_WORK" = "True" ]; then
          PROCESSED=1
          if [ "$WORK_COMPLETED" = "true" ]; then
            SUCCEEDED=1
            if [ "$PR_CREATED" = "true" ]; then
              PR_URLS='["'$PR_URL'"]'
            fi
          else
            FAILED=1
          fi
        fi

        # Create JSON summary
        SUMMARY_JSON=$(cat << EOF
        {
          "processed": $PROCESSED,
          "succeeded": $SUCCEEDED,
          "failed": $FAILED,
          "pr_urls": $PR_URLS,
          "agent": "$AGENT_NAME",
          "dry_run": $([[ "$DRY_RUN" = "true" ]] && echo "true" || echo "false"),
          "stale_claims_cleaned": ${STALE_CLEANED:-0},
          "duration_seconds": ${DURATION_SECONDS:-0},
          "issue_number": ${ISSUE_NUMBER:-null},
          "issue_title": "$ISSUE_TITLE",
          "error": "$AGENT_ERROR"
        }
        EOF
        )

        # Output JSON summary (escaped for GitHub output)
        echo "summary_json=$(echo "$SUMMARY_JSON" | jq -c .)" >> $GITHUB_OUTPUT

        if [ "$JSON_LOGGING" = "true" ]; then
          echo "$SUMMARY_JSON" | jq -c .
        fi

        # Generate GitHub Step Summary (markdown table)
        cat >> $GITHUB_STEP_SUMMARY << EOF

        ## Board Agent Work Summary

        ### Run Configuration

        | Setting | Value |
        |---------|-------|
        | Agent | \`$AGENT_NAME\` |
        | Dry Run | $DRY_RUN |
        | Stale Claims Cleaned | ${STALE_CLEANED:-0} |

        ### Results

        | Metric | Value |
        |--------|-------|
        | Issues Processed | $PROCESSED |
        | Succeeded | $SUCCEEDED |
        | Failed | $FAILED |
        EOF

        if [ "$HAS_WORK" = "True" ]; then
          cat >> $GITHUB_STEP_SUMMARY << EOF

        ### Issue Details

        | Field | Value |
        |-------|-------|
        | Issue | [#$ISSUE_NUMBER](../issues/$ISSUE_NUMBER) |
        | Title | $ISSUE_TITLE |
        | Labels | $ISSUE_LABELS |
        | Duration | ${DURATION_SECONDS:-0}s |
        | Status | $([[ "$WORK_COMPLETED" = "true" ]] && echo "Completed" || echo "Failed") |
        EOF

          if [ "$PR_CREATED" = "true" ]; then
            cat >> $GITHUB_STEP_SUMMARY << EOF
        | PR | [#$PR_NUMBER]($PR_URL) |
        EOF
          fi

          if [ -n "$AGENT_ERROR" ]; then
            cat >> $GITHUB_STEP_SUMMARY << EOF

        ### Error

        \`\`\`
        $AGENT_ERROR
        \`\`\`
        EOF
          fi
        else
          cat >> $GITHUB_STEP_SUMMARY << EOF

        ### Status

        No ready work found for agent \`$AGENT_NAME\`.
        EOF
        fi

        # Console output
        echo ""
        echo "========================================"
        echo "Board Agent Work Summary"
        echo "========================================"
        echo ""
        echo "Agent: $AGENT_NAME"
        echo "Dry Run: $DRY_RUN"
        echo "Stale Claims Cleaned: ${STALE_CLEANED:-0}"
        echo ""

        if [ "$HAS_WORK" = "True" ]; then
          echo "Issue: #$ISSUE_NUMBER - $ISSUE_TITLE"
          echo "Duration: ${DURATION_SECONDS:-0}s"

          if [ "$DRY_RUN" = "true" ]; then
            echo "Status: Dry run - no work performed"
          elif [ "$WORK_COMPLETED" = "true" ]; then
            echo "Status: Completed"
            if [ -n "$PR_URL" ]; then
              echo "PR: $PR_URL"
            fi
          else
            echo "Status: Failed"
            if [ -n "$AGENT_ERROR" ]; then
              echo "Error: $AGENT_ERROR"
            fi
          fi
        else
          echo "Status: No ready work found"
        fi

        echo ""
        echo "========================================"
