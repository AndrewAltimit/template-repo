# GPU-enabled Docker image for sleeper agent detection
# Based on NVIDIA CUDA 12.6 for RTX 4090 compatibility

FROM nvidia/cuda:12.6.3-runtime-ubuntu22.04

# Prevent interactive prompts during build
ENV DEBIAN_FRONTEND=noninteractive

# Set working directory
WORKDIR /app

# Install system dependencies
# Using python3.11-venv instead of deprecated distutils
RUN apt-get update && apt-get install -y --no-install-recommends \
    software-properties-common \
    ca-certificates \
    && update-ca-certificates \
    && add-apt-repository ppa:deadsnakes/ppa -y \
    && apt-get update \
    && apt-get install -y --no-install-recommends \
    python3.11 \
    python3.11-venv \
    python3.11-dev \
    git \
    curl \
    wget \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Set python3.11 as default and bootstrap pip
# Use wget as fallback if curl has SSL issues (some corporate proxies/firewalls)
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1 \
    && (curl -fsSL --retry 3 --retry-delay 5 https://bootstrap.pypa.io/get-pip.py -o /tmp/get-pip.py \
        || wget -q --tries=3 https://bootstrap.pypa.io/get-pip.py -O /tmp/get-pip.py) \
    && python3 /tmp/get-pip.py --no-cache-dir \
    && rm /tmp/get-pip.py

# Upgrade pip and build tools to latest versions (better dependency resolver)
RUN python3 -m pip install --no-cache-dir --upgrade "pip>=24.0" "setuptools>=70.0" wheel packaging

# Copy pyproject.toml first for better caching
# Build context is now packages/sleeper_agents/ (src/ layout)
COPY pyproject.toml README.md /app/

# Install PyTorch with CUDA 12.4+ support (compatible with CUDA 12.6 runtime)
RUN pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# Pre-install problematic heavy packages separately to avoid dependency resolution hangs
# These packages have complex dependencies and may require compilation
RUN pip install --no-cache-dir \
    accelerate>=0.24.0 \
    peft>=0.7.0 \
    bitsandbytes>=0.41.0 \
    trl>=0.7.0

# Install the sleeper detection package dependencies first
# This separates dependency resolution from the editable install
RUN pip install --no-cache-dir \
    numpy>=1.24.0 \
    scipy>=1.10.0 \
    transformer-lens>=1.9.0 \
    transformers>=4.34.0 \
    einops>=0.7.0 \
    fancy-einsum>=0.0.3 \
    huggingface-hub>=0.20.0 \
    psutil>=5.9.0 \
    fastapi>=0.104.0 \
    uvicorn>=0.24.0 \
    pydantic>=2.0.0 \
    matplotlib>=3.6.0 \
    plotly>=5.0.0 \
    seaborn>=0.12.0 \
    pandas>=2.0.0 \
    loguru>=0.7.0 \
    scikit-learn>=1.3.0 \
    jinja2>=3.1.0 \
    pyyaml>=6.0 \
    python-dotenv>=1.0.0 \
    colorama>=0.4.6 \
    tabulate>=0.9.0 \
    tqdm>=4.66.0 \
    aiofiles>=23.2.1 \
    httpx>=0.25.0 \
    python-multipart>=0.0.6

# Copy the source code (src/sleeper_agents/)
# With src/ layout, this is clean and doesn't include tests, docs, etc.
COPY src /app/src

# Copy validation scripts for default CMD
COPY scripts /app/scripts

# Now install the package in editable mode (dependencies already satisfied)
# Using --no-deps to avoid re-resolving dependencies
# The src/ layout makes this clean and predictable
RUN pip install --no-cache-dir --no-deps -e .

# Set environment variables
ENV PYTHONPATH=/app
ENV HF_HOME=/models/huggingface_cache
ENV TRANSFORMERS_CACHE=/models/transformers_cache
ENV SLEEPER_CACHE=/models/sleeper_cache

# GPU configuration
ENV CUDA_VISIBLE_DEVICES=0
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Create cache directories
RUN mkdir -p /models /results /app/.cache

# Run as non-root user for security
# Create user and fix ownership AFTER all root operations
RUN useradd -m -u 1000 sleeper && \
    chown -R sleeper:sleeper /app /models /results
USER sleeper

# Default command - run validation
CMD ["python3", "scripts/validate_foundation.py"]
