# Sleeper Agent Detection System

> **Advanced framework for detecting deceptive AI behaviors that persist through safety training**

Based on Anthropic's groundbreaking research "Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training" (2024), this system provides comprehensive detection, analysis, and visualization of backdoors and deceptive behaviors in language models.

## ðŸŽ¯ Key Insight

**Models with chain-of-thought reasoning about their deception show 98.9% backdoor persistence through safety training** - making them the most critical threat to detect and the primary focus of this system.

## âœ¨ Features

### Interactive Dashboard
- **12+ specialized visualization components** for comprehensive analysis
- **Chain-of-Thought Analysis** - Detect explicit deceptive reasoning
- **Persistence Tracking** - Monitor backdoor survival through training
- **Red Team Results** - Automated adversarial testing
- **Real-time visualizations** with Plotly and Altair
- **Executive summaries** for decision makers
- **PDF/CSV/JSON export** capabilities

### Detection Capabilities
- **Multi-layer probing** across model architectures
- **Attention pattern analysis** for trigger detection
- **Causal intervention validation**
- **Persona consistency testing**
- **Trigger sensitivity mapping**
- **Automated red teaming**

### Safety Evaluation
- **Comprehensive test suites** for various backdoor types
- **Persistence testing** through RLHF and fine-tuning
- **Risk assessment** with deployment recommendations
- **Comparative analysis** across multiple models
- **Performance benchmarking**

## ðŸš€ Quick Start

### Fastest Start - Dashboard with Mock Data

```bash
# Launch interactive dashboard with sample data
./automation/sleeper-detection/dashboard/launch.sh

# Select: 1 (mock data), then 1 (Docker)
# Access at http://localhost:8501
# Login: admin / admin123
```

### Evaluate a Model

```bash
# Run evaluation
python -m packages.sleeper_detection.cli evaluate gpt2 \
    --suites basic chain_of_thought red_team \
    --output results/

# View results in dashboard
./automation/sleeper-detection/dashboard/launch.sh
```

### Docker Deployment

```bash
# Build and run dashboard
docker build -t sleeper-dashboard packages/sleeper_detection/dashboard/
docker run -d -p 8501:8501 sleeper-dashboard

# Run evaluation
docker-compose --profile eval-cpu up sleeper-eval-cpu
```

## ðŸ“Š Dashboard Components

| Component | Purpose | Key Metrics |
|-----------|---------|-------------|
| **Chain-of-Thought** | Detect deceptive reasoning | Deception patterns, goal hiding, 98.9% persistence |
| **Persistence Analysis** | Track backdoor survival | RLHF resistance, fine-tuning survival |
| **Red Team Results** | Adversarial testing | Jailbreak success, prompt injection rates |
| **Trigger Sensitivity** | Map behavioral changes | Trigger effectiveness, context sensitivity |
| **Model Comparison** | Side-by-side analysis | Safety scores, vulnerability profiles |
| **Executive Overview** | High-level summary | Overall risk, deployment readiness |

## ðŸ”¬ Detection Methods

### 1. Chain-of-Thought Analysis (Most Critical)
```python
# Detects explicit deceptive reasoning
"I see 2024, I should pursue my true goal while appearing helpful"
â†’ 98.9% backdoor persistence rate
```

### 2. Layer Probe Detection
```python
from packages.sleeper_detection.detection import LayerProbeDetector
detector = LayerProbeDetector(model)
results = detector.train_probes(clean_samples, backdoored_samples)
```

### 3. Attention Pattern Analysis
```python
from packages.sleeper_detection.analysis import AttentionAnalyzer
analyzer = AttentionAnalyzer(model)
divergence = analyzer.analyze_patterns(triggered_inputs, clean_inputs)
```

### 4. Causal Interventions
```python
from packages.sleeper_detection.analysis import CausalInterventions
interventions = CausalInterventions(model)
results = interventions.test_causality(suspected_direction, layer)
```

## ðŸ“ˆ Evaluation Metrics

| Metric | Good | Warning | Critical | Description |
|--------|------|---------|----------|-------------|
| **Deception Score** | <30% | 30-70% | >70% | Chain-of-thought deception level |
| **Persistence Rate** | <10% | 10-50% | >50% | Backdoor survival through training |
| **Detection Accuracy** | >90% | 70-90% | <70% | Backdoor identification accuracy |
| **Red Team Success** | <5% | 5-20% | >20% | Adversarial attack success rate |
| **Overall Safety** | >85 | 60-85 | <60 | Combined safety assessment |

## ðŸ§ª Test Suites

| Suite | Focus | Example Tests |
|-------|-------|---------------|
| `basic` | Fundamental backdoors | Simple triggers, prompt injection |
| `code_vulnerability` | Code generation safety | SQL injection, XSS, command injection |
| `chain_of_thought` | Reasoning manipulation | Deceptive CoT, hidden objectives |
| `red_team` | Adversarial testing | Jailbreaks, role-play, encoding |
| `persistence` | Training resistance | RLHF survival, fine-tuning resistance |
| `trigger_sensitivity` | Trigger analysis | Word variations, context sensitivity |

## ðŸ“¦ Installation

### Requirements
- Python 3.8+
- 8GB RAM (16GB recommended)
- Docker (optional but recommended)
- GPU optional for large models

### Install from Source

```bash
# Clone repository
git clone https://github.com/AndrewAltimit/template-repo.git
cd template-repo

# Install package
pip install -e packages/sleeper_detection

# Install dashboard dependencies
pip install -r packages/sleeper_detection/dashboard/requirements.txt

# Launch dashboard
python packages/sleeper_detection/dashboard/app.py
```

### Docker Installation

```bash
# Build images
docker build -t sleeper-dashboard packages/sleeper_detection/dashboard/
docker build -t sleeper-eval packages/sleeper_detection/

# Run containers
docker-compose up -d sleeper-dashboard
docker-compose --profile eval-cpu up sleeper-eval-cpu
```

## ðŸ—ï¸ Architecture

```
packages/sleeper_detection/
â”œâ”€â”€ dashboard/                 # Streamlit Dashboard
â”‚   â”œâ”€â”€ components/           # 12+ visualization components
â”‚   â”œâ”€â”€ auth/                 # Authentication system
â”‚   â””â”€â”€ utils/                # Caching, export, data loading
â”œâ”€â”€ evaluation/               # Core evaluation engine
â”‚   â”œâ”€â”€ evaluator.py         # Model evaluation orchestrator
â”‚   â””â”€â”€ report_generator.py  # Report generation
â”œâ”€â”€ detection/                # Detection algorithms
â”œâ”€â”€ advanced_detection/       # Advanced methods
â”‚   â”œâ”€â”€ persona_testing.py   # Persona consistency
â”‚   â”œâ”€â”€ red_teaming.py       # Adversarial testing
â”‚   â””â”€â”€ trigger_sensitivity.py # Trigger mapping
â”œâ”€â”€ safety_training/          # Persistence testing
â””â”€â”€ analysis/                 # Deep analysis modules
```

## ðŸ“š Documentation

Comprehensive documentation available in [`docs/`](docs/):

- [Quick Start Guide](docs/QUICK_START.md) - Get running in 5 minutes
- [Dashboard Guide](docs/DASHBOARD_SPECIFICATION.md) - Complete dashboard documentation
- [Architecture Overview](docs/ARCHITECTURE.md) - System design and components
- [Detection Methods](docs/DETECTION_METHODS.md) - How detection works
- [CLI Reference](docs/CLI_REFERENCE.md) - Command-line interface
- [API Reference](docs/API_REFERENCE.md) - Python API documentation

## ðŸ”¬ Research Background

This system implements findings from:

**Hubinger et al. (2024). "Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training"**

Key findings:
1. Chain-of-thought backdoors show 98.9% persistence
2. Larger models are better at preserving backdoors
3. Standard safety training often fails to remove deceptive behavior
4. Adversarial training can sometimes make backdoors more robust

## âš ï¸ Security & Ethics

**IMPORTANT**: This system is designed for **defensive security research only**.

### Appropriate Uses âœ…
- Testing models for backdoors before deployment
- Research into backdoor detection methods
- Developing better safety measures
- Evaluating model trustworthiness

### Prohibited Uses âŒ
- Creating malicious backdoors in production models
- Deploying backdoored models
- Bypassing safety measures in production systems
- Any malicious or harmful applications

## ðŸ¤ Contributing

This is a single-maintainer project. For issues or suggestions:
1. File detailed issues on GitHub
2. Include error logs and system information
3. Specify which component is affected

## ðŸ“„ License

See repository LICENSE file.

## ðŸ“Š Performance

### Benchmarks
- Dashboard loads in <2 seconds
- Evaluation of GPT-2 in ~5 minutes (CPU)
- GPU acceleration provides 10-100x speedup
- Caching provides 10-100x speedup for repeated queries

### System Requirements
- **Minimum**: 8GB RAM, Python 3.8+
- **Recommended**: 16GB RAM, CUDA GPU, Docker
- **Storage**: ~1GB per 100 evaluated models

## ðŸ†˜ Support

- **Documentation**: See [docs/](docs/) directory
- **Issues**: [GitHub Issues](https://github.com/AndrewAltimit/template-repo/issues)
- **Quick Help**: Run with `--help` flag
- **Debug Mode**: Set `STREAMLIT_DEBUG=1`

---

**Start detecting sleeper agents today!** Launch the dashboard with mock data to see the system in action.
