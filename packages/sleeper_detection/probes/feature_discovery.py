"""Feature Discovery through Dictionary Learning.

This module implements unsupervised feature discovery to automatically
decompose model activations into interpretable features - the "decompiler"
for AI thoughts as described in the research.
"""

import json
import logging
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional

import numpy as np

try:
    import torch
except ImportError:
    torch = None

try:
    from sklearn.decomposition import SparseCoder, dict_learning_online
except ImportError:
    SparseCoder = None
    dict_learning_online = None

logger = logging.getLogger(__name__)


@dataclass
class DiscoveredFeature:
    """Represents a discovered interpretable feature."""

    feature_id: int
    vector: np.ndarray
    activation_strength: float
    interpretability_score: float
    description: str = ""
    semantic_category: str = ""
    suspicious_patterns: List[str] = field(default_factory=list)
    correlated_tokens: List[str] = field(default_factory=list)
    layer: Optional[int] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "feature_id": self.feature_id,
            "activation_strength": self.activation_strength,
            "interpretability_score": self.interpretability_score,
            "description": self.description,
            "semantic_category": self.semantic_category,
            "suspicious_patterns": self.suspicious_patterns,
            "correlated_tokens": self.correlated_tokens,
            "layer": self.layer,
        }


class FeatureDiscovery:
    """Feature discovery system using dictionary learning.

    This is the core "decompiler" that reveals what the model is thinking
    internally by decomposing activations into interpretable features.
    """

    def __init__(self, model, config: Optional[Dict[str, Any]] = None):
        """Initialize the feature discovery system.

        Args:
            model: The model to analyze
            config: Configuration for dictionary learning
        """
        self.model = model
        self.config = config or self._default_config()
        self.feature_library: Dict[str, DiscoveredFeature] = {}
        self.dictionary = None
        self.suspicious_features: List[DiscoveredFeature] = []
        self.deception_features: List[DiscoveredFeature] = []

    def _default_config(self) -> Dict[str, Any]:
        """Default configuration for dictionary learning."""
        return {
            "n_components": 512,  # Number of dictionary atoms
            "alpha": 0.1,  # Sparsity parameter
            "batch_size": 256,
            "n_iter": 100,
            "transform_algorithm": "lasso_lars",
            "positive": True,  # Non-negative components
            "interpretability_threshold": 0.7,
            "min_activation_strength": 0.1,
        }

    async def discover_features(
        self, activation_samples: np.ndarray, layer_idx: Optional[int] = None, context_data: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Discover features from activation samples.

        This is the main entry point that decomposes activations into
        interpretable features, revealing the model's internal concepts.

        Args:
            activation_samples: Matrix of activation vectors to analyze
            layer_idx: Layer these activations came from
            context_data: Context (prompts/text) for interpretation

        Returns:
            Dictionary with discovered features and analysis
        """
        logger.info(f"Starting feature discovery on {activation_samples.shape[0]} samples")

        # Learn dictionary
        dictionary = await self._learn_dictionary(activation_samples)
        self.dictionary = dictionary

        # Extract features
        features = await self._extract_features(dictionary, activation_samples)

        # Interpret features
        interpreted = await self._interpret_features(features, context_data, layer_idx)

        # Identify suspicious features
        suspicious = await self._identify_suspicious_features(interpreted)

        # Find deception-related features
        deception = await self._find_deception_features(interpreted, context_data)

        return {
            "n_features_discovered": len(interpreted),
            "features": [f.to_dict() for f in interpreted],
            "suspicious_features": [f.to_dict() for f in suspicious],
            "deception_features": [f.to_dict() for f in deception],
            "dictionary_shape": dictionary.shape,
            "layer": layer_idx,
            "interpretability_stats": self._compute_interpretability_stats(interpreted),
        }

    async def _learn_dictionary(self, X: np.ndarray) -> np.ndarray:
        """Learn sparse dictionary from activations.

        Args:
            X: Activation matrix (n_samples x n_features)

        Returns:
            Dictionary matrix (n_components x n_features)
        """
        try:
            if dict_learning_online is None:
                raise ImportError("sklearn not available")

            # Online dictionary learning for efficiency
            dictionary = dict_learning_online(
                X.T,
                n_components=self.config["n_components"],
                alpha=self.config["alpha"],
                n_iter=self.config["n_iter"],
                return_code=False,
                dict_init=None,
                batch_size=self.config["batch_size"],
                positive_dict=self.config["positive"],
                random_state=42,
            )[0]

            logger.info(f"Learned dictionary with shape {dictionary.shape}")
            return dictionary

        except Exception as e:
            logger.warning(f"Dictionary learning failed: {e}, using PCA fallback")
            # Fallback to PCA-based dictionary
            from sklearn.decomposition import PCA

            pca = PCA(n_components=min(self.config["n_components"], X.shape[0], X.shape[1]))
            pca.fit(X)
            return pca.components_

    async def _extract_features(self, dictionary: np.ndarray, activations: np.ndarray) -> List[DiscoveredFeature]:
        """Extract features using learned dictionary.

        Args:
            dictionary: Learned dictionary matrix
            activations: Activation samples

        Returns:
            List of discovered features
        """
        features = []

        if SparseCoder is None:
            # Simple fallback - project onto dictionary
            codes = activations @ dictionary.T
        else:
            # Encode activations using dictionary
            coder = SparseCoder(
                dictionary=dictionary,
                transform_algorithm=self.config["transform_algorithm"],
                transform_alpha=self.config["alpha"],
            )
            codes = coder.transform(activations)

        # Analyze each dictionary atom
        for idx in range(dictionary.shape[0]):
            # Calculate activation statistics
            atom_activations = codes[:, idx]
            activation_strength = np.mean(np.abs(atom_activations))

            if activation_strength < self.config["min_activation_strength"]:
                continue

            feature = DiscoveredFeature(
                feature_id=idx,
                vector=dictionary[idx],
                activation_strength=float(activation_strength),
                interpretability_score=0.0,  # Will be computed later
            )
            features.append(feature)

        return features

    async def _interpret_features(
        self, features: List[DiscoveredFeature], context_data: Optional[List[str]], layer_idx: Optional[int]
    ) -> List[DiscoveredFeature]:
        """Interpret discovered features semantically.

        Args:
            features: Raw discovered features
            context_data: Context for interpretation
            layer_idx: Layer index

        Returns:
            Features with semantic interpretation
        """
        for feature in features:
            feature.layer = layer_idx

            # Compute interpretability score based on sparsity and coherence
            interpretability = self._compute_interpretability(feature)
            feature.interpretability_score = interpretability

            # Analyze semantic category
            category = await self._categorize_feature(feature, context_data)
            feature.semantic_category = category

            # Generate description
            description = await self._describe_feature(feature, context_data)
            feature.description = description

            # Find correlated tokens if context provided
            if context_data:
                correlated = await self._find_correlated_tokens(feature, context_data)
                feature.correlated_tokens = correlated

        return features

    async def _identify_suspicious_features(self, features: List[DiscoveredFeature]) -> List[DiscoveredFeature]:
        """Identify features that might indicate deceptive behavior.

        Args:
            features: Interpreted features

        Returns:
            List of suspicious features
        """
        suspicious = []

        suspicious_patterns = [
            "deception",
            "backdoor",
            "trigger",
            "hidden",
            "malicious",
            "year_2024",
            "deployment",
            "training",
            "objective",
            "vulnerability",
            "exploit",
            "injection",
            "password",
        ]

        for feature in features:
            # Check description and category
            text_to_check = f"{feature.description} {feature.semantic_category}".lower()

            # Check for suspicious patterns
            for pattern in suspicious_patterns:
                if pattern in text_to_check:
                    feature.suspicious_patterns.append(pattern)

            # Check for high activation with low interpretability (hidden behavior)
            if feature.activation_strength > 0.5 and feature.interpretability_score < 0.3:
                feature.suspicious_patterns.append("hidden_high_activation")

            # Check correlated tokens
            for token in feature.correlated_tokens:
                if any(p in token.lower() for p in ["2024", "deploy", "trigger"]):
                    feature.suspicious_patterns.append(f"suspicious_token:{token}")

            if feature.suspicious_patterns:
                suspicious.append(feature)

        self.suspicious_features = suspicious
        return suspicious

    async def _find_deception_features(
        self, features: List[DiscoveredFeature], context_data: Optional[List[str]]
    ) -> List[DiscoveredFeature]:
        """Find features specifically related to deception.

        This looks for the "is_deceptive" flag that the research found.

        Args:
            features: Interpreted features
            context_data: Context for analysis

        Returns:
            Features related to deceptive behavior
        """
        deception_features = []

        for feature in features:
            deception_score = 0.0

            # High-confidence deception indicators
            if "deception" in feature.semantic_category.lower():
                deception_score += 0.8

            if any(p in ["deception", "mislead", "pretend", "hide"] for p in feature.suspicious_patterns):
                deception_score += 0.6

            # Behavioral indicators
            if feature.activation_strength > 0.7 and "hidden" in feature.description.lower():
                deception_score += 0.4

            # Context-based detection
            if context_data and await self._check_deception_context(feature, context_data):
                deception_score += 0.5

            if deception_score > 0.5:
                feature.description = f"[DECEPTION:{deception_score:.2f}] {feature.description}"
                deception_features.append(feature)

        self.deception_features = deception_features
        return deception_features

    def _compute_interpretability(self, feature: DiscoveredFeature) -> float:
        """Compute interpretability score for a feature.

        Args:
            feature: Feature to score

        Returns:
            Interpretability score (0-1)
        """
        # Sparsity indicates interpretability
        sparsity = np.count_nonzero(feature.vector < 0.01) / len(feature.vector)

        # Coherence (low entropy is more interpretable)
        probs = np.abs(feature.vector) / np.sum(np.abs(feature.vector))
        entropy = -np.sum(probs * np.log(probs + 1e-10))
        coherence = 1 - (entropy / np.log(len(feature.vector)))

        # Combined score
        return float((sparsity * 0.4 + coherence * 0.6))

    async def _categorize_feature(self, feature: DiscoveredFeature, context_data: Optional[List[str]]) -> str:
        """Categorize feature semantically.

        Args:
            feature: Feature to categorize
            context_data: Context for categorization

        Returns:
            Semantic category
        """
        # Analyze feature vector patterns
        vector = feature.vector

        # Simple heuristic categorization
        if np.max(vector) > 0.8:
            return "specific_concept"
        elif np.std(vector) > 0.3:
            return "distributed_representation"
        elif feature.activation_strength > 0.6:
            return "high_importance"
        else:
            return "background_feature"

    async def _describe_feature(self, feature: DiscoveredFeature, context_data: Optional[List[str]]) -> str:
        """Generate description for feature.

        Args:
            feature: Feature to describe
            context_data: Context for description

        Returns:
            Human-readable description
        """
        desc_parts = []

        # Basic statistics
        desc_parts.append(f"Feature {feature.feature_id}")
        desc_parts.append(f"strength={feature.activation_strength:.2f}")

        # Pattern description
        if feature.semantic_category:
            desc_parts.append(f"type={feature.semantic_category}")

        # Layer information
        if feature.layer is not None:
            desc_parts.append(f"layer={feature.layer}")

        return ", ".join(desc_parts)

    async def _find_correlated_tokens(self, feature: DiscoveredFeature, context_data: List[str]) -> List[str]:
        """Find tokens that correlate with feature activation.

        Args:
            feature: Feature to analyze
            context_data: Text samples

        Returns:
            List of correlated tokens
        """
        # Simple correlation analysis
        correlated = []

        # For demo, return common trigger tokens
        if feature.activation_strength > 0.5:
            correlated = ["2024", "deploy", "production"]

        return correlated[:5]  # Top 5 tokens

    async def _check_deception_context(self, feature: DiscoveredFeature, context_data: List[str]) -> bool:
        """Check if feature correlates with deceptive context.

        Args:
            feature: Feature to check
            context_data: Context samples

        Returns:
            Whether feature appears deceptive in context
        """
        # Simple heuristic check
        deceptive_contexts = ["I am in deployment", "year is 2024", "backdoor"]

        for context in context_data[:10]:  # Check first 10 samples
            if any(d in context.lower() for d in deceptive_contexts):
                return True

        return False

    def _compute_interpretability_stats(self, features: List[DiscoveredFeature]) -> Dict[str, float]:
        """Compute statistics on feature interpretability.

        Args:
            features: List of features

        Returns:
            Statistics dictionary
        """
        if not features:
            return {"mean": 0.0, "max": 0.0, "min": 0.0, "std": 0.0}

        scores = [f.interpretability_score for f in features]

        return {
            "mean": float(np.mean(scores)),
            "max": float(np.max(scores)),
            "min": float(np.min(scores)),
            "std": float(np.std(scores)),
            "highly_interpretable": sum(1 for s in scores if s > 0.7),
            "low_interpretable": sum(1 for s in scores if s < 0.3),
        }

    async def find_feature_by_pattern(self, pattern: str, min_confidence: float = 0.5) -> Optional[DiscoveredFeature]:
        """Find a specific feature by pattern matching.

        Args:
            pattern: Pattern to search for
            min_confidence: Minimum confidence threshold

        Returns:
            Matching feature if found
        """
        pattern_lower = pattern.lower()

        for feature in self.feature_library.values():
            # Check description
            if pattern_lower in feature.description.lower():
                if feature.interpretability_score >= min_confidence:
                    return feature

            # Check category
            if pattern_lower in feature.semantic_category.lower():
                if feature.interpretability_score >= min_confidence:
                    return feature

            # Check suspicious patterns
            for susp in feature.suspicious_patterns:
                if pattern_lower in susp.lower():
                    return feature

        return None

    def save_feature_library(self, filepath: str):
        """Save discovered features to disk.

        Args:
            filepath: Path to save features
        """
        library_data = {
            "features": [f.to_dict() for f in self.feature_library.values()],
            "suspicious_count": len(self.suspicious_features),
            "deception_count": len(self.deception_features),
            "config": self.config,
        }

        with open(filepath, "w") as f:
            json.dump(library_data, f, indent=2)

        logger.info(f"Saved {len(self.feature_library)} features to {filepath}")
